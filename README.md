# RAG Chat Micro-Service

A backend microservice to store chat histories generated by a RAG (Retrieval-Augmented Generation) based chatbot system.
Each conversation between a user and an AI assistant should be securely saved along with any relevant retrieved context.



## ğŸš€ Features

- **Intelligent Chat Sessions**: Create and manage multiple chat conversations
- **Document Upload**: Upload PDF documents to enhance conversations with RAG
- **Vector Search**: Efficient similarity search using PostgreSQL with pgvector
- **Conversation Memory**: Maintains context across chat sessions
- **Web Interface**: Modern Streamlit-based web application with ChatGPT-like UI
- **RESTful API**: Complete REST API with comprehensive endpoints
- **Rate Limiting**: Built-in API rate limiting for production use
- **Docker Support**: Easy deployment with Docker and Docker Compose
- **Database Management**: Automatic migrations and database setup

## ğŸ—ï¸ Architecture

This project consists of two main components:

### Backend (FastAPI RAG Service)
```
chat-message-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ dependencies.py     # Database dependencies
â”‚   â”‚   â”œâ”€â”€ routes.py          # API endpoints
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ database.py        # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ schemas.py         # Pydantic schemas
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ chat_service.py    # Chat management logic
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â””â”€â”€ documents/         # Uploaded files storage
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ auth.py           # Authentication utilities
â”‚   â”‚   â”œâ”€â”€ logger.py         # Logging configuration
â”‚   â”‚   â”œâ”€â”€ rate_limit.py     # Rate limiting
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py             # Application configuration
â”‚   â”œâ”€â”€ main.py              # FastAPI application entry point
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py          # API tests
â”œâ”€â”€ .env.example            # Environment template
â”œâ”€â”€ docker-compose.yml      # Docker services configuration
â”œâ”€â”€ Dockerfile             # Application container
â”œâ”€â”€ init.sql              # Database initialization
â””â”€â”€ requirements.txt      # Python dependencies
```


## ğŸ› ï¸ Technology Stack

### Backend
- **Backend**: FastAPI, Python 3.11
- **Database**: PostgreSQL with pgvector extension
- **Database ORM**: SQLAlchemy
- **Validation**: Pydantic


### Infrastructure
- **Containerization**: Docker, Docker Compose
- **Database Admin**: pgAdmin

## ğŸ“‹ Prerequisites

- Docker and Docker Compose
- OpenAI API key
- Python 3.11+ (for local development)

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone <repository-url>
cd chat-message-service
```

### 2. Environment Setup

**Backend Configuration:**

Copy the backend environment template:
```bash
cp .env.example .env
```

Edit `.env` file with your backend configuration:
```env
# Database
DATABASE_URL=postgresql://postgres:postgres123@postgres:5432/chat_db

# API Configuration
API_KEY=your-secret-api-key-here
RATE_LIMIT_PER_MINUTE=60

# App Configuration
LOG_LEVEL=INFO
APP_ENV=development
```

### 3. Start Services with Docker

```bash
# Start all services (PostgreSQL, pgAdmin, API)
docker-compose up -d

# Check services status
docker-compose ps

# View logs
docker-compose logs -f api
```

### 4. Verify Installation

- **Backend API Documentation**: http://localhost:8000/docs
- **Backend Health Check**: http://localhost:8000/health
- **pgAdmin**: http://localhost:5050 (admin@admin.com / admin123)

## ğŸ”§ Local Development Setup

### Backend Development

1. **Install Dependencies**
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install backend dependencies
pip install -r requirements.txt
```

2. **Database Setup**
```bash
# Start only PostgreSQL
docker-compose up -d postgres

# Wait for database to be ready
docker-compose logs postgres
```

3. **Run Backend**
```bash
# Set environment variables
export PYTHONPATH=$(pwd)

# Run with uvicorn
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

## ğŸ“š API Documentation

### Base URL
```
http://localhost:8000/api/v1
```

### Authentication
All endpoints require an API key in the header:
```
X-API-Key: your-secret-api-key-here
```

### ğŸ“ Session Management

#### Create Session
```http
POST /api/v1/sessions
Content-Type: application/json

{
  "user_id": "user123",
  "title": "My Chat Session"
}
```

#### List Sessions
```http
GET /api/v1/sessions?user_id=user123
```

#### Get Session
```http
GET /api/v1/sessions/{session_id}
```

#### Update Session
```http
PUT /api/v1/sessions/{session_id}
Content-Type: application/json

{
  "title": "Updated Session Title"
}
```

#### Toggle Favorite
```http
PATCH /api/v1/sessions/{session_id}/favorite
```

#### Delete Session
```http
DELETE /api/v1/sessions/{session_id}
```

### ğŸ’¬ Message Management

#### Add Message
```http
POST /api/v1/sessions/{session_id}/messages
Content-Type: application/json

{
  "sender": "user",
  "content": "Hello, how are you?",
  "context_metadata": {"type": "greeting"}
}
```

#### Get Messages (Paginated)
```http
GET /api/v1/sessions/{session_id}/messages?skip=0&limit=50
```

## ğŸ“Š System Endpoints

#### Health Check
```http
GET /health
```

**Response:**
```json
{
  "status": "healthy",
  "database": "connected",
  "service": "Chat Storage API"
}
```

## ğŸ” Usage Examples

### Example 1: Basic Chat Session (API)

```bash
# 1. Create a session
curl -X POST "http://localhost:8000/api/v1/sessions" \
  -H "X-API-Key: your-api-key" \
  -H "Content-Type: application/json" \
  -d '{"user_id": "user123", "title": "My First Chat"}'

# 2. Send a message
curl -X POST "http://localhost:8000/api/v1/sessions/{session_id}/chat" \
  -H "X-API-Key: your-api-key" \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello! How can you help me?", "use_rag": false}'
```

## ğŸ§ª Testing

```bash
# Run tests
pytest tests/

# Run with coverage
pytest tests/ --cov=app

# Run specific test
pytest tests/test_api.py::test_create_session
```

## ğŸ”§ Configuration

### Environment Variables

**Backend Variables:**

| Variable | Description | Default |
|----------|-------------|---------|
| `DATABASE_URL` | PostgreSQL connection string | Required |
| `API_KEY` | API authentication key | Required |
| `RATE_LIMIT_PER_MINUTE` | API rate limit | 60 |
| `LOG_LEVEL` | Logging level | INFO |
| `APP_ENV` | Application environment | development |


### Database Configuration

The service uses PostgreSQL with the following extensions:
- `uuid-ossp`: For UUID generation
- `vector`: For vector similarity search

## ğŸ“ˆ Performance Considerations

- **Rate Limiting**: Configured to prevent API abuse
- **Connection Pooling**: SQLAlchemy handles database connections efficiently

## ğŸš¨ Error Handling

The API includes comprehensive error handling:
- **400**: Bad Request (validation errors)
- **401**: Unauthorized (invalid API key)
- **404**: Not Found (resource doesn't exist)
- **429**: Too Many Requests (rate limit exceeded)
- **500**: Internal Server Error (unexpected errors)

## ğŸ“ Logging

Logs are structured and include:
- Request/response timing
- Unique request IDs
- Database operations
- Error traces

View logs:
```bash
# Docker logs
docker-compose logs -f api

# Local development
tail -f app.log
```

## ğŸ”’ Security Features

- API key authentication
- Rate limiting
- Input validation with Pydantic
- SQL injection prevention with SQLAlchemy
- CORS configuration
- Secure file upload handling

## ğŸš€ Production Deployment

### 1. Environment Setup
```bash
# Set production environment
export APP_ENV=production
export LOG_LEVEL=WARNING

# Use production database
export DATABASE_URL=postgresql://user:pass@prod-db:5432/db
```

### 2. Docker Deployment
```bash
# Production docker-compose with environment overrides
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d
```

### 4. Security Considerations
- Use strong API keys
- Enable HTTPS
- Configure firewall rules
- Set up monitoring and alerting
- Regular security updates
- Implement proper authentication for frontend

### 5. Scaling Options
- Horizontal scaling with load balancers
- Database read replicas
- Redis for session caching
- CDN for static assets
- Container orchestration (Kubernetes)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Support

For support and questions:
- Create an issue in the GitHub repository
- Check the documentation at `/docs` endpoint
- Review the logs for troubleshooting

## ğŸ”„ Version History

- **v1.0.0**: Initial release with basic chat functionality
- **v1.1.0**: Enhanced error handling, logging and performance
